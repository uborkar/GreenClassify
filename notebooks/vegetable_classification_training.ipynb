{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40ba50d",
   "metadata": {},
   "source": [
    "# GreenClassify: Deep Learning-Based Vegetable Image Classification\n",
    "\n",
    "This notebook demonstrates the complete pipeline for building a CNN-based vegetable image classification system.\n",
    "\n",
    "## Project Overview\n",
    "- **Objective**: Classify vegetable images into 15 categories\n",
    "- **Model**: Convolutional Neural Network (CNN)\n",
    "- **Framework**: TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b405e",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Download the Vegetable Image Dataset from Kaggle. The dataset contains:\n",
    "- Train: 15,000 images\n",
    "- Test: 3,000 images\n",
    "- Validation: 3,000 images\n",
    "\n",
    "Each folder contains subfolders for 15 different vegetable categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle API (for Google Colab)\n",
    "# Upload your kaggle.json file first\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!kaggle datasets download -d misrakahmed/vegetable-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "!unzip vegetable-image-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce264bdb",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252fb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39904e",
   "metadata": {},
   "source": [
    "## 3. Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "train_path = \"/content/Vegetable Images/train\"\n",
    "validation_path = \"/content/Vegetable Images/validation\"\n",
    "test_path = \"/content/Vegetable Images/test\"\n",
    "\n",
    "# Get image categories\n",
    "image_categories = os.listdir(train_path)\n",
    "print(f\"Number of categories: {len(image_categories)}\")\n",
    "print(f\"Categories: {image_categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d742598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot sample images from each category\n",
    "def plot_images(image_categories, base_path):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, cat in enumerate(image_categories):\n",
    "        # Load images for the ith category\n",
    "        image_path = base_path + '/' + cat\n",
    "        images_in_folder = os.listdir(image_path)\n",
    "        first_image_of_folder = images_in_folder[0]\n",
    "        first_image_path = image_path + '/' + first_image_of_folder\n",
    "        img = load_img(first_image_path)\n",
    "        img_arr = img_to_array(img) / 255.0\n",
    "        \n",
    "        plt.subplot(3, 5, i + 1)\n",
    "        plt.imshow(img_arr)\n",
    "        plt.title(cat)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Each Category', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_images(image_categories, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per category\n",
    "def count_images_per_category(base_path):\n",
    "    categories = os.listdir(base_path)\n",
    "    counts = {}\n",
    "    for cat in categories:\n",
    "        cat_path = os.path.join(base_path, cat)\n",
    "        counts[cat] = len(os.listdir(cat_path))\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images_per_category(train_path)\n",
    "print(\"Training images per category:\")\n",
    "for cat, count in train_counts.items():\n",
    "    print(f\"  {cat}: {count}\")\n",
    "print(f\"\\nTotal training images: {sum(train_counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b20eb",
   "metadata": {},
   "source": [
    "## 4. Data Pre-Processing\n",
    "\n",
    "Configure ImageDataGenerator for data augmentation and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a23b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Configure ImageDataGenerator for training with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Configure ImageDataGenerator for validation and test (only rescaling)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_image_generator = val_test_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_image_generator = val_test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the class encodings done by the generators\n",
    "class_map = dict((v, k) for k, v in train_image_generator.class_indices.items())\n",
    "print(\"Class Mapping:\")\n",
    "print(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad1302",
   "metadata": {},
   "source": [
    "## 5. Model Building\n",
    "\n",
    "Build a Convolutional Neural Network (CNN) for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2170856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "NUM_CLASSES = len(image_categories)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()  # Model object\n",
    "\n",
    "# Add Convolutional Layers\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\n",
    "model.add(MaxPooling2D(2,))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "# Flatten the feature map\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e1b5c",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9928edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 15000 // BATCH_SIZE\n",
    "VALIDATION_STEPS = 3000 // BATCH_SIZE\n",
    "\n",
    "hist = model.fit(\n",
    "    train_image_generator,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=val_image_generator,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436daf1",
   "metadata": {},
   "source": [
    "## 7. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b969b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "h = hist.history\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h['loss'], c='red', label='Training Loss')\n",
    "plt.plot(h['val_loss'], c='red', linestyle='--', label='Validation Loss')\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h['accuracy'], c='blue', label='Training Accuracy')\n",
    "plt.plot(h['val_accuracy'], c='blue', linestyle='--', label='Validation Accuracy')\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51127621",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93771b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_image_generator)\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94814b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = model.predict(test_image_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_image_generator.classes\n",
    "\n",
    "print(f\"Number of predictions: {len(predicted_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_names = list(train_image_generator.class_indices.keys())\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562a78c",
   "metadata": {},
   "source": [
    "## 9. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in H5 format\n",
    "model.save('vegetable_classification.h5')\n",
    "print(\"Model saved as 'vegetable_classification.h5'\")\n",
    "\n",
    "# Also save in SavedModel format\n",
    "model.save('vegetable_classification_savedmodel')\n",
    "print(\"Model saved in SavedModel format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b842b65",
   "metadata": {},
   "source": [
    "## 10. Test the Model with Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('vegetable_classification.h5', compile=False)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict vegetable from image\n",
    "def predict_vegetable(image_path, model):\n",
    "    # Class mapping\n",
    "    op = {\n",
    "        0: 'Bean', \n",
    "        1: 'Bitter_Gourd', \n",
    "        2: 'Bottle_Gourd', \n",
    "        3: 'Brinjal', \n",
    "        4: 'Broccoli', \n",
    "        5: 'Cabbage', \n",
    "        6: 'Capsicum', \n",
    "        7: 'Carrot', \n",
    "        8: 'Cauliflower', \n",
    "        9: 'Cucumber', \n",
    "        10: 'Papaya', \n",
    "        11: 'Potato', \n",
    "        12: 'Pumpkin', \n",
    "        13: 'Radish', \n",
    "        14: 'Tomato'\n",
    "    }\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = load_img(image_path, target_size=(150, 150))\n",
    "    img_arr = img_to_array(img)\n",
    "    img_input = np.expand_dims(img_arr, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = np.argmax(model.predict(img_input))\n",
    "    \n",
    "    # Display results\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predicted: {op[pred]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return op[pred]\n",
    "\n",
    "# Test with a sample image\n",
    "sample_image = test_path + \"/Tomato/\" + os.listdir(test_path + \"/Tomato\")[0]\n",
    "result = predict_vegetable(sample_image, loaded_model)\n",
    "print(f\"Prediction: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple random images\n",
    "import random\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    # Select random category and image\n",
    "    random_cat = random.choice(image_categories)\n",
    "    cat_path = os.path.join(test_path, random_cat)\n",
    "    random_image = random.choice(os.listdir(cat_path))\n",
    "    image_path = os.path.join(cat_path, random_image)\n",
    "    \n",
    "    # Load and predict\n",
    "    img = load_img(image_path, target_size=(150, 150))\n",
    "    img_arr = img_to_array(img)\n",
    "    img_input = np.expand_dims(img_arr, axis=0)\n",
    "    pred = np.argmax(loaded_model.predict(img_input, verbose=0))\n",
    "    \n",
    "    # Display\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"True: {random_cat}\\nPred: {class_map[pred]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_predictions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ac3f5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Data Collection**: Downloaded vegetable image dataset from Kaggle\n",
    "2. **Data Analysis**: Explored the dataset structure and visualized samples\n",
    "3. **Data Preprocessing**: Applied image augmentation using ImageDataGenerator\n",
    "4. **Model Building**: Built a CNN with Conv2D, MaxPooling2D, Dense layers\n",
    "5. **Model Training**: Trained with early stopping callback\n",
    "6. **Model Evaluation**: Evaluated on test data with classification report\n",
    "7. **Model Saving**: Saved in H5 format for Flask deployment\n",
    "\n",
    "The saved model (`vegetable_classification.h5`) can now be used in the Flask web application for real-time vegetable classification."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
